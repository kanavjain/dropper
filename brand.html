<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>3D Audio Visualizer with Webcam Texture</title>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            height: 100%;
            background-color: black;
            touch-action: none;
        }
        #startButton {
            position: absolute;
            top: 20px;
            left: 20px;
            padding: 12px 24px;
            font-size: 16px;
            cursor: pointer;
            z-index: 1;
        }
        /* Hide the button after clicking */
        #startButton.hidden {
            display: none;
        }
    </style>
</head>
<body>
    <canvas id="glCanvas"></canvas>
    <button id="startButton">Start Audio Visualization</button>

    <script>
        const canvas = document.getElementById('glCanvas');
        const gl = canvas.getContext('webgl');

        if (!gl) {
            alert('WebGL not supported in this browser.');
            throw new Error('WebGL not supported');
        }

        // Resize canvas to fit the window
        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        // Vertex shader source code
        const vertexShaderSource = `
            attribute vec3 a_position;
            attribute vec2 a_texCoord;
            uniform mat4 u_modelViewMatrix;
            uniform mat4 u_projectionMatrix;
            varying vec2 v_texCoord;
            void main() {
                gl_Position = u_projectionMatrix * u_modelViewMatrix * vec4(a_position, 1.0);
                v_texCoord = a_texCoord;
            }
        `;

        // Fragment shader source code
        const fragmentShaderSource = `
            precision highp float;
            varying vec2 v_texCoord;
            uniform sampler2D u_webcamTexture;
            void main() {
                vec4 color = texture2D(u_webcamTexture, v_texCoord);
                gl_FragColor = color;
            }
        `;

        // Function to create shader and program
        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);

            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('Shader compile failed:', gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                throw new Error('Shader compile failed');
            }
            return shader;
        }

        const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
        const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);

        // Create and link the program
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);

        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            console.error('Program link failed:', gl.getProgramInfoLog(program));
            gl.deleteProgram(program);
            throw new Error('Program link failed');
        }

        gl.useProgram(program);

        // Define the cube vertices and texture coordinates
        const positions = new Float32Array([
            // Front face
            -1.0, -1.0,  1.0, // Bottom-left
             1.0, -1.0,  1.0, // Bottom-right
             1.0,  1.0,  1.0, // Top-right
            -1.0,  1.0,  1.0, // Top-left
            // Back face
            -1.0, -1.0, -1.0, // ...
             1.0, -1.0, -1.0,
             1.0,  1.0, -1.0,
            -1.0,  1.0, -1.0,
        ]);

        const texCoords = new Float32Array([
            // Front face
            0.0, 1.0, // Bottom-left
            1.0, 1.0, // Bottom-right
            1.0, 0.0, // Top-right
            0.0, 0.0, // Top-left
            // Back face
            1.0, 1.0, // ...
            0.0, 1.0,
            0.0, 0.0,
            1.0, 0.0,
        ]);

        const indices = new Uint16Array([
            // Front face
            0, 1, 2,   0, 2, 3,
            // Back face
            4, 5, 6,   4, 6, 7,
            // Top face
            3, 2, 6,   3, 6, 7,
            // Bottom face
            0, 1, 5,   0, 5, 4,
            // Right face
            1, 2, 6,   1, 6, 5,
            // Left face
            0, 3, 7,   0, 7, 4,
        ]);

        // Create buffers
        const positionBuffer = gl.createBuffer();
        const texCoordBuffer = gl.createBuffer();
        const indexBuffer = gl.createBuffer();

        // Bind positions
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);
        const positionLocation = gl.getAttribLocation(program, 'a_position');
        gl.enableVertexAttribArray(positionLocation);
        gl.vertexAttribPointer(positionLocation, 3, gl.FLOAT, false, 0, 0);

        // Bind texture coordinates
        gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, texCoords, gl.STATIC_DRAW);
        const texCoordLocation = gl.getAttribLocation(program, 'a_texCoord');
        gl.enableVertexAttribArray(texCoordLocation);
        gl.vertexAttribPointer(texCoordLocation, 2, gl.FLOAT, false, 0, 0);

        // Bind indices
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
        gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW);

        // Get uniform locations
        const modelViewMatrixLocation = gl.getUniformLocation(program, 'u_modelViewMatrix');
        const projectionMatrixLocation = gl.getUniformLocation(program, 'u_projectionMatrix');
        const webcamTextureLocation = gl.getUniformLocation(program, 'u_webcamTexture');

        // Create a texture for the webcam feed
        const webcamTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, webcamTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 2, 2, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);

        // Set texture parameters
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.MIRRORED_REPEAT);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.MIRRORED_REPEAT);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

        // Create a video element to capture webcam feed
        const video = document.createElement('video');
        video.autoplay = true;
        video.playsInline = true;
        video.style.display = 'none';
        document.body.appendChild(video);

        // Variables for animation
        let rotation = [0, 0, 0];
        let lastTime = 0;

        // Variables for audio
        let audioAnalyser = null;

        // Variables for device orientation
        let orientation = [0.0, 0.0, 0.0];

        // Audio setup
        function setupAudio() {
            navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                audioAnalyser = audioContext.createAnalyser();
                audioAnalyser.fftSize = 256;
                source.connect(audioAnalyser);
            }).catch(err => {
                alert('Microphone access denied.');
                console.error('Error accessing microphone:', err);
            });
        }

        // Webcam setup
        function setupWebcam() {
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                video.play();
                requestAnimationFrame(render);
            }).catch(err => {
                alert('Webcam access denied.');
                console.error('Error accessing webcam:', err);
            });
        }

        // Start audio and webcam on button click
        const startButton = document.getElementById('startButton');
        startButton.addEventListener('click', () => {
            setupAudio();
            setupWebcam();
            startButton.classList.add('hidden');
        });

        // Handle device orientation
        window.addEventListener('deviceorientation', event => {
            const gamma = event.gamma || 0; // Left to right tilt [-90,90]
            const beta = event.beta || 0;   // Front to back tilt [-180,180]
            const alpha = event.alpha || 0; // Compass direction [0,360]

            orientation = [
                beta * Math.PI / 180,   // X-axis rotation
                gamma * Math.PI / 180,  // Y-axis rotation
                alpha * Math.PI / 180   // Z-axis rotation
            ];
        });

        // Include the glMatrix library for matrix operations
        const script = document.createElement('script');
        script.src = 'https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.8.1/gl-matrix-min.js';
        document.head.appendChild(script);

        script.onload = function() {
            // Start rendering if the webcam is already set up
            if (video.readyState >= 2) {
                requestAnimationFrame(render);
            }
        };

        // Render loop
        function render(currentTime) {
            const deltaTime = currentTime - lastTime;
            lastTime = currentTime;

            // Clear the canvas
            gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
            gl.enable(gl.DEPTH_TEST);

            // Update the webcam texture
            if (video.readyState >= 2) {
                gl.bindTexture(gl.TEXTURE_2D, webcamTexture);
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, video);
            }

            // Calculate rotation based on time and device orientation
            rotation[0] += deltaTime * 0.0005 + orientation[0] * 0.1;
            rotation[1] += deltaTime * 0.0003 + orientation[1] * 0.1;
            rotation[2] += deltaTime * 0.0004 + orientation[2] * 0.1;

            // Update rotation based on audio (e.g., bass frequency)
            if (audioAnalyser) {
                const bufferLength = audioAnalyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                audioAnalyser.getByteFrequencyData(dataArray);

                // Use bass frequencies to affect the rotation speed
                const bass = dataArray.slice(0, bufferLength / 4);
                const bassAvg = bass.reduce((a, b) => a + b, 0) / bass.length / 255.0;
                rotation[1] += bassAvg * 0.05;
            }

            // Set up projection matrix
            const fieldOfView = 45 * Math.PI / 180;
            const aspect = canvas.clientWidth / canvas.clientHeight;
            const zNear = 0.1;
            const zFar = 100.0;
            const projectionMatrix = mat4.create();
            mat4.perspective(projectionMatrix, fieldOfView, aspect, zNear, zFar);

            // Set up model view matrix
            const modelViewMatrix = mat4.create();
            mat4.translate(modelViewMatrix, modelViewMatrix, [0.0, 0.0, -6.0]);
            mat4.rotateX(modelViewMatrix, modelViewMatrix, rotation[0]);
            mat4.rotateY(modelViewMatrix, modelViewMatrix, rotation[1]);
            mat4.rotateZ(modelViewMatrix, modelViewMatrix, rotation[2]);

            // Set uniforms
            gl.uniformMatrix4fv(projectionMatrixLocation, false, projectionMatrix);
            gl.uniformMatrix4fv(modelViewMatrixLocation, false, modelViewMatrix);

            // Set texture uniform
            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, webcamTexture);
            gl.uniform1i(webcamTextureLocation, 0);

            // Draw the cube
            gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_SHORT, 0);

            requestAnimationFrame(render);
        }
    </script>
</body>
</html>
