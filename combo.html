<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Immersive 3D Music Visualizer with Transitions</title>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            height: 100%;
            background-color: black;
            font-family: Arial, sans-serif;
        }
        canvas {
            display: block;
        }
        #controls {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 10;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0, 0, 0, 0.8);
        }
        #controls label {
            color: #ffffff;
            font-size: 14px;
            font-weight: bold;
            display: block;
            margin-bottom: 5px;
        }
        #controls input[type=range], #controls select {
            width: 150px;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <canvas id="glCanvas"></canvas>
    <div id="controls">
        <button id="startAudio">Start Audio Interaction</button>
        <label>
            Sensitivity: 
            <input type="range" id="sensitivity" min="0.5" max="2.0" step="0.1" value="1.0">
        </label>
        <label>
            Visual Mode: 
            <select id="visualMode">
                <option value="waves">Waves</option>
                <option value="particles">Particles</option>
                <option value="knot">Torus Knot</option>
            </select>
        </label>
    </div>
    <script>
        // Get canvas and WebGL context
        const canvas = document.getElementById("glCanvas");
        const gl = canvas.getContext("webgl");

        // Resize canvas
        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        // Shaders for different modes
        const shaders = {
            waves: {
                fragment: `
                    precision mediump float;
                    uniform float u_time;
                    uniform float u_audioData;
                    uniform vec2 u_resolution;
                    varying vec2 v_uv;

                    void main() {
                        vec2 uv = v_uv - 0.5;
                        uv *= 2.0;

                        float dist = length(uv);
                        float angle = atan(uv.y, uv.x);

                        float wave = sin(dist * 10.0 - u_time * 2.0 + u_audioData * 5.0);
                        vec3 color = vec3(0.5 + 0.5 * sin(angle + wave), 0.5 + 0.5 * cos(angle + wave), 1.0 - dist);
                        color *= 1.0 + u_audioData * 2.0;

                        gl_FragColor = vec4(color, 1.0);
                    }
                `,
            },
            particles: {
                fragment: `
                    precision mediump float;
                    uniform float u_time;
                    uniform float u_audioData;
                    uniform vec2 u_resolution;
                    varying vec2 v_uv;

                    void main() {
                        vec2 uv = v_uv - 0.5;
                        uv *= 2.0;

                        float dist = length(uv);
                        float particle = step(0.95, fract(sin(dist * 20.0 + u_time * 4.0) * 43758.5453));

                        vec3 color = vec3(particle * u_audioData);
                        gl_FragColor = vec4(color, 1.0);
                    }
                `,
            },
            knot: {
                fragment: `
                    precision mediump float;
                    uniform float u_time;
                    uniform float u_audioData;
                    uniform vec2 u_resolution;
                    varying vec2 v_uv;

                    void main() {
                        vec2 uv = v_uv - 0.5;
                        uv *= 2.0;

                        float dist = length(uv);
                        float ripple = sin(dist * 15.0 - u_time * 3.0) * 0.5;

                        vec3 color = vec3(0.5 + 0.5 * sin(u_time * ripple), 0.5 + 0.5 * cos(u_time + dist), 1.0);
                        gl_FragColor = vec4(color, 1.0);
                    }
                `,
            },
        };

        let currentProgram, nextProgram;
        let currentTime = 0.0;
        let transitionProgress = 0.0;
        const transitionDuration = 1.5; // 1.5 seconds transition
        let isTransitioning = false;

        // Create and compile shader
        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        // Set up geometry
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
            -1, -1,
             1, -1,
            -1,  1,
            -1,  1,
             1, -1,
             1,  1,
        ]), gl.STATIC_DRAW);

        let analyser;
        let time = 0.0;
        let audioData = 0.0;

        // Create WebGL program
        function createProgram(fragmentShaderSource) {
            const vertexShaderSource = `
                attribute vec2 a_position;
                varying vec2 v_uv;
                void main() {
                    v_uv = a_position * 0.5 + 0.5;
                    gl_Position = vec4(a_position, 0.0, 1.0);
                }
            `;
            const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
            const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);

            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);

            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error(gl.getProgramInfoLog(program));
                gl.deleteProgram(program);
                throw new Error("Program failed to link");
            }

            return program;
        }

        function useProgram(program) {
            currentProgram = program;
            gl.useProgram(currentProgram);

            const positionLocation = gl.getAttribLocation(currentProgram, 'a_position');
            gl.enableVertexAttribArray(positionLocation);
            gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

            const resolutionLocation = gl.getUniformLocation(currentProgram, 'u_resolution');
            gl.uniform2f(resolutionLocation, canvas.width, canvas.height);
        }

        function switchMode(mode) {
            const fragmentShaderSource = shaders[mode].fragment;
            nextProgram = createProgram(fragmentShaderSource);
            isTransitioning = true;
            transitionProgress = 0.0;
        }

        // Audio setup
        async function setupAudio() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                getAudioData();
            } catch (err) {
                alert('Unable to access microphone. Please allow microphone permissions.');
                console.error("Error capturing audio: ", err);
            }
        }

        function getAudioData() {
            requestAnimationFrame(getAudioData);
            if (analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
                audioData = average / 128.0; // Normalize
            }
        }

        // Transition handling
        function handleTransition() {
            if (isTransitioning) {
                transitionProgress += 1.0 / (transitionDuration * 60); // Assume 60 FPS

                if (transitionProgress >= 1.0) {
                    transitionProgress = 1.0;
                    isTransitioning = false;
                    useProgram(nextProgram);
                }

                const blendFactor = transitionProgress;
                const timeLocation1 = gl.getUniformLocation(currentProgram, 'u_time');
                const audioDataLocation1 = gl.getUniformLocation(currentProgram, 'u_audioData');
                gl.uniform1f(timeLocation1, time);
                gl.uniform1f(audioDataLocation1, audioData);

                gl.clear(gl.COLOR_BUFFER_BIT);
                gl.drawArrays(gl.TRIANGLES, 0, 6);

                // Set next program for blending
                gl.useProgram(nextProgram);
                const timeLocation2 = gl.getUniformLocation(nextProgram, 'u_time');
                const audioDataLocation2 = gl.getUniformLocation(nextProgram, 'u_audioData');
                gl.uniform1f(timeLocation2, time);
                gl.uniform1f(audioDataLocation2, audioData);

                gl.enable(gl.BLEND);
                gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);

                gl.drawArrays(gl.TRIANGLES, 0, 6);
                gl.disable(gl.BLEND);

                // Reset program to current one
                gl.useProgram(currentProgram);
            }
        }

        // Render loop
        function render() {
            time += 0.01;

            const timeLocation = gl.getUniformLocation(currentProgram, 'u_time');
            const audioDataLocation = gl.getUniformLocation(currentProgram, 'u_audioData');
            gl.uniform1f(timeLocation, time);
            gl.uniform1f(audioDataLocation, audioData);

            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.drawArrays(gl.TRIANGLES, 0, 6);

            handleTransition();

            requestAnimationFrame(render);
        }

        // Event listeners
        document.getElementById("startAudio").addEventListener("click", setupAudio);

        document.getElementById("visualMode").addEventListener("change", (event) => {
            const mode = event.target.value;
            switchMode(mode);
        });

        // Initial setup
        switchMode("waves");
        requestAnimationFrame(render);
    </script>
</body>
</html>
