<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PlayCanvas Microphone Visualizer</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            overflow: hidden;
        }
    </style>
</head>
<body>

    <script src="https://code.playcanvas.com/playcanvas-stable.min.js"></script>

    <script>
        // Set up the PlayCanvas application
        const canvas = document.createElement('canvas');
        document.body.appendChild(canvas);
        const app = new pc.Application(canvas, {});

        // Set canvas to full screen
        app.setCanvasFillMode(pc.FILLMODE_FILL_WINDOW);
        app.setCanvasResolution(pc.RESOLUTION_AUTO);
        app.start();

        // Set background color
        app.scene.skyboxMip = 0;
        app.scene.ambientLight = new pc.Color(0.5, 0.5, 0.5);

        // Create camera
        const camera = new pc.Entity();
        camera.addComponent("camera", {
            clearColor: new pc.Color(0, 0, 0)
        });
        camera.translate(0, 0, 20);
        app.root.addChild(camera);

        // Create light
        const light = new pc.Entity();
        light.addComponent("light");
        light.setLocalEulerAngles(45, 0, 0);
        app.root.addChild(light);

        // Create an array of visualizer bars
        const bars = [];
        const numBars = 32;
        for (let i = 0; i < numBars; i++) {
            const bar = new pc.Entity();
            bar.addComponent("model", {
                type: "box"
            });
            bar.setLocalScale(0.5, 1, 0.5);
            bar.setLocalPosition(i - numBars / 2, 0, 0);
            app.root.addChild(bar);
            bars.push(bar);
        }

        let audioContext, analyser, dataArray;

        // Function to start microphone capture
        function startMicCapture() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(function (stream) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);

                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 64; // Adjust the size to match numBars
                    dataArray = new Uint8Array(analyser.frequencyBinCount);

                    source.connect(analyser);

                    // Update the visualizer
                    app.on("update", updateVisualizer);
                })
                .catch(function (err) {
                    console.error('Error accessing microphone: ' + err);
                });
        }

        // Update visualizer bars based on audio data
        function updateVisualizer(dt) {
            if (analyser) {
                analyser.getByteFrequencyData(dataArray);

                for (let i = 0; i < bars.length; i++) {
                    const scaleY = dataArray[i] / 255 * 10; // Scale the height based on frequency
                    bars[i].setLocalScale(0.5, Math.max(0.5, scaleY), 0.5); // Avoid zero scale
                }
            }
        }

        // Start microphone capture when the page loads
        window.onload = function () {
            startMicCapture();
        };

        // Handle window resizing
        window.addEventListener("resize", function () {
            app.resizeCanvas(canvas.width, canvas.height);
        });
    </script>
</body>
</html>
