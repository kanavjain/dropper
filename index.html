<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Sound to Tactile Sensation Visualizer with WebGPU and WebGL</title>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            height: 100%;
            background-color: #000000; /* OLED black */
        }
        canvas {
            display: block;
            width: 100vw;
            height: 100vh;
        }
    </style>
</head>
<body>
    <canvas id="gpuCanvas"></canvas>
    <script type="module">
        import { GPUBufferUsage, GPUShaderStage } from 'https://cdn.jsdelivr.net/npm/@webgpu/types@1.0.0/dist/index.js';

        // Check for WebGPU support
        if (!navigator.gpu) {
            console.error('WebGPU is not supported by your browser. Falling back to WebGL.');
            // Fallback to WebGL if WebGPU is not supported
            const canvas = document.getElementById('gpuCanvas');
            const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

            if (!gl) {
                console.error('WebGL not supported');
                throw new Error('WebGL not supported');
            }

            // Resize canvas
            function resizeCanvas() {
                canvas.width = window.innerWidth;
                canvas.height = window.innerHeight;
                gl.viewport(0, 0, canvas.width, canvas.height);
            }
            window.addEventListener('resize', resizeCanvas);
            resizeCanvas();

            // Compile shader
            function compileShader(source, type) {
                const shader = gl.createShader(type);
                gl.shaderSource(shader, source);
                gl.compileShader(shader);
                if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                    console.error('Shader compile failed: ' + gl.getShaderInfoLog(shader));
                    gl.deleteShader(shader);
                    throw new Error('Shader compile error');
                }
                return shader;
            }

            // Vertex shader source
            const vertexShaderSource = `
                attribute vec2 a_position;
                varying vec2 v_uv;
                void main() {
                    v_uv = a_position * 0.5 + 0.5;
                    gl_Position = vec4(a_position, 0.0, 1.0);
                }
            `;

            // Fragment shader source
            const fragmentShaderSource = `
                precision mediump float;
                uniform float u_time;
                uniform float u_low_freq;
                uniform float u_mid_freq;
                uniform float u_high_freq;
                varying vec2 v_uv;
                void main() {
                    vec2 uv = v_uv - 0.5;
                    float dist = length(uv);
                    float angle = atan(uv.y, uv.x);
                    float lowPattern = 0.5 + 0.5 * sin(10.0 * dist - u_time + angle * 5.0) * u_low_freq;
                    float midPattern = 0.5 + 0.5 * cos(15.0 * dist - u_time * 1.5 + angle * 4.0) * u_mid_freq;
                    float highPattern = 0.5 + 0.5 * sin(20.0 * dist - u_time * 2.0 + angle * 6.0) * u_high_freq;
                    float combined = mix(lowPattern, midPattern, 0.5) + highPattern * 0.5;
                    gl_FragColor = vec4(vec3(combined), 1.0);
                }
            `;

            // Create and link program
            const vertexShader = compileShader(vertexShaderSource, gl.VERTEX_SHADER);
            const fragmentShader = compileShader(fragmentShaderSource, gl.FRAGMENT_SHADER);
            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);

            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error('Program link failed: ' + gl.getProgramInfoLog(program));
                throw new Error('Program link error');
            }
            gl.useProgram(program);

            // Set up geometry
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
                -1, -1,
                1, -1,
                -1, 1,
                -1, 1,
                1, -1,
                1, 1,
            ]), gl.STATIC_DRAW);

            const positionLocation = gl.getAttribLocation(program, 'a_position');
            gl.enableVertexAttribArray(positionLocation);
            gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

            // Set up uniforms
            const timeLocation = gl.getUniformLocation(program, 'u_time');
            const lowFreqLocation = gl.getUniformLocation(program, 'u_low_freq');
            const midFreqLocation = gl.getUniformLocation(program, 'u_mid_freq');
            const highFreqLocation = gl.getUniformLocation(program, 'u_high_freq');

            // Audio setup for beat detection and frequency analysis
            navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then(stream => {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                function updateAudioData() {
                    analyser.getByteFrequencyData(dataArray);
                    const lowFreq = dataArray.slice(0, bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;
                    const midFreq = dataArray.slice(bufferLength / 3, 2 * bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;
                    const highFreq = dataArray.slice(2 * bufferLength / 3, bufferLength).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;

                    // Beat detection based on low frequency threshold
                    if (lowFreq > 0.5) {
                        canvas.style.transform = 'scale(1.05)';
                        setTimeout(() => {
                            canvas.style.transform = 'scale(1)';
                        }, 100);
                    }

                    gl.uniform1f(lowFreqLocation, lowFreq);
                    gl.uniform1f(midFreqLocation, midFreq);
                    gl.uniform1f(highFreqLocation, highFreq);

                    requestAnimationFrame(updateAudioData);
                }
                updateAudioData();
            }).catch(err => {
                console.error('Error accessing microphone: ' + err);
            });

            // Render loop
            function render(time) {
                time *= 0.001; // Convert time to seconds

                // Set uniforms
                gl.uniform1f(timeLocation, time);

                // Draw
                gl.clearColor(0, 0, 0, 1);
                gl.clear(gl.COLOR_BUFFER_BIT);
                gl.drawArrays(gl.TRIANGLES, 0, 6);

                requestAnimationFrame(render);
            }
            requestAnimationFrame(render);
        } else {
            // Set up WebGPU
            const canvas = document.getElementById('gpuCanvas');
            const adapter = await navigator.gpu.requestAdapter();
            const device = await adapter.requestDevice();
            const context = canvas.getContext('webgpu');
            const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
            context.configure({ device, format: presentationFormat });

            // Create shaders with advanced capabilities like compute shaders
            const shaderModule = device.createShaderModule({
                code: `
                @vertex fn vertex_main(@builtin(vertex_index) index: u32) -> @builtin(position) vec4<f32> {
                    var positions = array<vec2<f32>, 3>(
                        vec2<f32>(0.0, 0.5),
                        vec2<f32>(-0.5, -0.5),
                        vec2<f32>(0.5, -0.5)
                    );
                    return vec4<f32>(positions[index], 0.0, 1.0);
                }

                @fragment fn fragment_main(@builtin(position) pos: vec4<f32>) -> @location(0) vec4<f32> {
                    let uv = pos.xy * 0.5 + vec2<f32>(0.5);
                    let dist = length(uv - vec2<f32>(0.5));
                    let angle = atan2(uv.y - 0.5, uv.x - 0.5);
                    let pattern = 0.5 + 0.5 * sin(10.0 * dist - angle * 5.0);
                    let color = vec3<f32>(0.0, 1.0, 0.0) * pattern;
                    return vec4<f32>(color, 1.0);
                }

                @compute fn compute_main(@builtin(global_invocation_id) id: vec3<u32>) {
                    // Simple computation (e.g., calculating pixel values for visualization)
                    let value: f32 = f32(id.x % 256u) / 255.0;
                    // Here, you could apply a Fast Fourier Transform (FFT) or any other GPU computation for visual feedback
                }
                `
            });

            // Set up render pipeline
            const pipeline = device.createRenderPipeline({
                layout: "auto",
                vertex: {
                    module: shaderModule,
                    entryPoint: "vertex_main",
                },
                fragment: {
                    module: shaderModule,
                    entryPoint: "fragment_main",
                    targets: [{ format: presentationFormat }],
                },
                primitive: {
                    topology: "triangle-list",
                },
            });

            // Set up a command encoder for rendering
            function render() {
                const commandEncoder = device.createCommandEncoder();
                const textureView = context.getCurrentTexture().createView();

                const renderPassDescriptor = {
                    colorAttachments: [
                        {
                            view: textureView,
                            loadValue: { r: 0, g: 0, b: 0, a: 1 },
                            storeOp: "store",
                        },
                    ],
                };

                const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
                passEncoder.setPipeline(pipeline);
                passEncoder.draw(3, 1, 0, 0);
                passEncoder.end();

                device.queue.submit([commandEncoder.finish()]);
            }

            // Animation loop
            function frame() {
                render();
                requestAnimationFrame(frame);
            }
            requestAnimationFrame(frame);
        }
    </script>
</body>
</html>
