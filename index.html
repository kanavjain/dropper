<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Trippy Synesthetic Visualizer with WebGL</title>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            height: 100%;
            background-color: #000000; /* OLED black */
        }
        canvas {
            display: block;
            width: 100vw;
            height: 100vh;
        }
        #controls {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 10;
        }
    </style>
</head>
<body>
    <canvas id="gpuCanvas"></canvas>
    <div id="controls">
        <select id="audioSelect">
            <option value="mic">Microphone</option>
            <option value="device">Device Audio</option>
        </select>
        <button id="darkModeToggle">Toggle Dark Mode</button>
        <button id="vibrationToggle">Toggle Vibrations</button>
    </div>
    <script>
        const canvas = document.getElementById('gpuCanvas');
        const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

        if (!gl) {
            console.error('WebGL not supported');
            throw new Error('WebGL not supported');
        }

        let darkMode = false;
        let vibrationsEnabled = true;

        // Resize canvas function
        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        // Shader functions
        function compileShader(source, type) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('Shader compile failed: ' + gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                throw new Error('Shader compile error');
            }
            return shader;
        }

        function createShaderProgram(vertexSource, fragmentSource) {
            const vertexShader = compileShader(vertexSource, gl.VERTEX_SHADER);
            const fragmentShader = compileShader(fragmentSource, gl.FRAGMENT_SHADER);
            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);
            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error('Program link failed: ' + gl.getProgramInfoLog(program));
                throw new Error('Program link error');
            }
            return program;
        }

        // Vertex and fragment shaders
        const vertexShaderSource = `
            attribute vec2 a_position;
            varying vec2 v_uv;
            void main() {
                v_uv = a_position * 0.5 + 0.5;
                gl_Position = vec4(a_position, 0.0, 1.0);
            }
        `;

        const fragmentShaderSource = `
            precision mediump float;
            uniform float u_time;
            uniform float u_low_freq;
            uniform float u_mid_freq;
            uniform float u_high_freq;
            uniform vec2 u_touch0;
            uniform vec2 u_touch1;
            uniform vec3 u_orientation;
            uniform bool u_dark_mode;
            varying vec2 v_uv;

            // Function to create smoother noise patterns
            float noise(vec2 p) {
                return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
            }

            // Fractal Brownian Motion for smooth distortion
            float fbm(vec2 p) {
                float f = 0.0;
                f += 0.5000 * noise(p); p *= 2.02;
                f += 0.2500 * noise(p); p *= 2.03;
                f += 0.1250 * noise(p); p *= 2.01;
                f += 0.0625 * noise(p);
                return f;
            }

            void main() {
                vec2 uv = v_uv - 0.5;
                float dist = length(uv);
                float angle = atan(uv.y, uv.x);

                // Add flowing distortions to the visuals
                float flow = sin(u_time + dist * 10.0 + fbm(uv * 10.0)) * 0.1;
                uv += flow * 0.2;

                // Create a base color with smooth gradient transitions
                vec3 baseColor = vec3(
                    0.5 + 0.5 * sin(u_time + angle + u_low_freq * 5.0),
                    0.5 + 0.5 * cos(u_time * 1.5 + angle * 2.0 + u_mid_freq * 4.0),
                    0.5 + 0.5 * sin(u_time * 0.8 + angle * 3.0 + u_high_freq * 6.0)
                );

                // Modify brightness for dark mode
                if (u_dark_mode) {
                    baseColor *= 0.2;
                }

                // Add fluid-like "melting" distortions
                float fbmValue = fbm(uv * 6.0 + u_time * 0.8);
                baseColor.rgb += fbmValue * 0.15;

                // Create radial gradient glow effect
                float radialGradient = smoothstep(0.8, 0.1, dist) * (1.0 + sin(u_time * 2.5 + dist * 20.0) * 0.2);
                baseColor *= radialGradient;

                // Add glow effect to simulate bright blooming visuals
                float glow = exp(-dist * 8.0) * (u_low_freq + u_mid_freq + u_high_freq);
                if (u_dark_mode) {
                    glow *= 0.1;
                }
                baseColor += vec3(glow * 0.5, glow * 0.7, glow * 1.0);

                // Adding a touch ripple effect to create interactive distortion
                float touchEffect0 = 0.0;
                float touchEffect1 = 0.0;
                if (length(u_touch0) > 0.0) {
                    touchEffect0 = 0.3 / length(uv - (u_touch0 - 0.5));
                }
                if (length(u_touch1) > 0.0) {
                    touchEffect1 = 0.3 / length(uv - (u_touch1 - 0.5));
                }
                baseColor += vec3(touchEffect0 + touchEffect1);

                // Final output color with increased brightness for glowing effect
                gl_FragColor = vec4(baseColor, 1.0);
            }
        `;

        const program = createShaderProgram(vertexShaderSource, fragmentShaderSource);
        gl.useProgram(program);

        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
            -1, -1,
            1, -1,
            -1, 1,
            -1, 1,
            1, -1,
            1, 1,
        ]), gl.STATIC_DRAW);

        const positionLocation = gl.getAttribLocation(program, 'a_position');
        gl.enableVertexAttribArray(positionLocation);
        gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

        const timeLocation = gl.getUniformLocation(program, 'u_time');
        const lowFreqLocation = gl.getUniformLocation(program, 'u_low_freq');
        const midFreqLocation = gl.getUniformLocation(program, 'u_mid_freq');
        const highFreqLocation = gl.getUniformLocation(program, 'u_high_freq');
        const touch0Location = gl.getUniformLocation(program, 'u_touch0');
        const touch1Location = gl.getUniformLocation(program, 'u_touch1');
        const orientationLocation = gl.getUniformLocation(program, 'u_orientation');
        const darkModeLocation = gl.getUniformLocation(program, 'u_dark_mode');

        let audioContext, analyser, source;
        const audioSelect = document.getElementById('audioSelect');
        const darkModeToggle = document.getElementById('darkModeToggle');
        const vibrationToggle = document.getElementById('vibrationToggle');

        audioSelect.addEventListener('change', initializeAudio);
        darkModeToggle.addEventListener('click', () => {
            darkMode = !darkMode;
        });
        vibrationToggle.addEventListener('click', () => {
            vibrationsEnabled = !vibrationsEnabled;
        });

        function initializeAudio() {
            if (audioContext) {
                audioContext.close();
            }

            navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();

                if (audioSelect.value === 'mic') {
                    source = audioContext.createMediaStreamSource(stream);
                } else {
                    const audioElement = new Audio();
                    audioElement.crossOrigin = 'anonymous';
                    source = audioContext.createMediaElementSource(audioElement);
                    source.connect(audioContext.destination);
                    audioElement.play();
                }

                source.connect(analyser);
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                let lastVibrateTime = 0;

                function vibrateBasedOnAudio(lowFreq, midFreq, highFreq) {
                    const intensity = Math.max(lowFreq, midFreq, highFreq);
                    const currentTime = Date.now();
                    if (vibrationsEnabled && intensity > 0.7 && currentTime - lastVibrateTime > 500) {
                        if (navigator.vibrate) {
                            navigator.vibrate([intensity * 100, 50, intensity * 100]);
                        }
                        lastVibrateTime = currentTime;
                    }
                }

                let orientation = { alpha: 0, beta: 0, gamma: 0 };
                window.addEventListener('deviceorientation', (event) => {
                    orientation.alpha = event.alpha;
                    orientation.beta = event.beta;
                    orientation.gamma = event.gamma;
                });

                let touches = [
                    { x: 0.0, y: 0.0 },
                    { x: 0.0, y: 0.0 }
                ];

                canvas.addEventListener('touchstart', (event) => {
                    updateTouches(event.touches);
                    event.preventDefault();
                });

                canvas.addEventListener('touchmove', (event) => {
                    updateTouches(event.touches);
                    event.preventDefault();
                });

                canvas.addEventListener('touchend', (event) => {
                    updateTouches(event.touches);
                    event.preventDefault();
                });

                function updateTouches(touchList) {
                    for (let i = 0; i < touches.length; i++) {
                        if (i < touchList.length) {
                            const touch = touchList[i];
                            touches[i].x = (touch.clientX / window.innerWidth) * 2.0 - 1.0;
                            touches[i].y = 1.0 - (touch.clientY / window.innerHeight) * 2.0;
                        } else {
                            touches[i].x = 0;
                            touches[i].y = 0;
                        }
                    }
                }

                function updateAudioData() {
                    analyser.getByteFrequencyData(dataArray);
                    const lowFreq = dataArray.slice(0, bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;
                    const midFreq = dataArray.slice(bufferLength / 3, 2 * bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;
                    const highFreq = dataArray.slice(2 * bufferLength / 3, bufferLength).reduce((sum, value) => sum + value, 0) / (bufferLength / 3) / 256.0;

                    gl.uniform1f(lowFreqLocation, lowFreq);
                    gl.uniform1f(midFreqLocation, midFreq);
                    gl.uniform1f(highFreqLocation, highFreq);
                    gl.uniform3f(orientationLocation, orientation.alpha / 360.0, orientation.beta / 90.0, orientation.gamma / 90.0);

                    gl.uniform2f(touch0Location, touches[0].x, touches[0].y);
                    gl.uniform2f(touch1Location, touches[1].x, touches[1].y);

                    vibrateBasedOnAudio(lowFreq, midFreq, highFreq);

                    requestAnimationFrame(updateAudioData);
                }
                updateAudioData();
            }).catch(err => {
                console.error('Error accessing microphone: ' + err);
            });
        }

        // Render loop
        function render(time) {
            time *= 0.001; // Convert time to seconds
            gl.uniform1f(timeLocation, time);
            gl.clearColor(0, 0, 0, 1);
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.drawArrays(gl.TRIANGLES, 0, 6);
            requestAnimationFrame(render);
        }
        requestAnimationFrame(render);
    </script>
</body>
</html>
