<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Sound to Tactile Sensation Visualizer</title>
    <style>
        body, html {
            margin: 0;
            overflow: hidden;
            height: 100%;
            background-color: #000000; /* OLED black */
        }
        canvas {
            display: block;
            width: 100vw;
            height: 100vh;
        }
    </style>
</head>
<body>
    <canvas id="glCanvas"></canvas>
    <script>
        const canvas = document.getElementById('glCanvas');
        const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

        if (!gl) {
            console.error('WebGL not supported');
            throw new Error('WebGL not supported');
        }

        // Resize canvas
        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        // Compile shader
        function compileShader(source, type) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('Shader compile failed: ' + gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                throw new Error('Shader compile error');
            }
            return shader;
        }

        // Vertex shader source
        const vertexShaderSource = `
            attribute vec2 a_position;
            varying vec2 v_uv;
            void main() {
                v_uv = a_position * 0.5 + 0.5;
                gl_Position = vec4(a_position, 0.0, 1.0);
            }
        `;

        // Fragment shader source for visual effects
        const fragmentShaderSource = `
            precision mediump float;
            uniform float u_time;
            uniform vec2 u_resolution;
            uniform float u_audio;
            uniform vec3 u_orientation;
            uniform vec2 u_touch;
            varying vec2 v_uv;

            vec2 rotate(vec2 v, float a) {
                float s = sin(a);
                float c = cos(a);
                return vec2(c * v.x - s * v.y, s * v.x + c * v.y);
            }
            
            float bitcrush(float value, float bits) {
                return floor(value * bits) / bits;
            }

            void main() {
                vec2 uv = v_uv - 0.5;
                uv.x *= u_resolution.x / u_resolution.y;
                float time = u_time * 0.1;
                vec2 flow = uv;
                
                // Apply orientation-based distortion
                flow.x += u_orientation.x * 0.1;
                flow.y += u_orientation.y * 0.1;
                
                // Apply touch interaction
                float touch_dist = length(flow - u_touch);
                flow += 0.05 / (touch_dist + 0.01) * vec2(sin(u_time), cos(u_time));
                
                // Add fluid-like distortion with audio reactivity and z-axis
                for (int i = 0; i < 8; i++) {
                    flow = rotate(flow, sin(time + length(flow) * 3.0 + float(i) * 0.3) * 0.5);
                    flow += vec2(sin(flow.y * 8.0 + time + u_audio * 2.0), cos(flow.x * 8.0 + time + u_audio * 1.5)) * 0.03;
                }
                
                float z = sin(length(flow) * 10.0 - u_time * 0.5 + u_audio * 2.0) * 0.5 + 0.5;
                float bitcrushed_z = bitcrush(z, 8.0);

                // Low-contrast color with chromatic aberration and glitch effect
                vec3 color = vec3(bitcrushed_z * 0.2, bitcrushed_z * 0.3, bitcrushed_z * 0.4);
                color.r += 0.05 * sin(u_time + flow.x * 20.0);
                color.g += 0.05 * cos(u_time + flow.y * 20.0);
                
                // Add particle-like effect
                float particle = sin(flow.x * 20.0 + u_time * 5.0) * cos(flow.y * 20.0 + u_time * 5.0);
                color += 0.1 * vec3(particle, particle, particle);
                
                // Fractal zoom effect for depth
                for (int i = 0; i < 2; i++) { // Reduced number of iterations to save battery
                    flow = rotate(flow, sin(time * 2.0 + float(i) * 1.5) * 0.5);
                    flow *= 1.1; // Reduced scaling to lower computation
                    float fractal = abs(sin(length(flow) * 5.0 + u_time * 0.5));
                    color += 0.03 * vec3(fractal, fractal, fractal); // Lower intensity for battery efficiency
                }
                
                // Glitchy pixel-sorted lines
                if (mod(gl_FragCoord.y, 15.0) < 1.0) { // Increased interval to reduce frequency of effect
                    color = mix(color, vec3(0.0), 0.5);
                }
                
                gl_FragColor = vec4(color, 1.0);
            }
        `;

        // Create and link program
        const vertexShader = compileShader(vertexShaderSource, gl.VERTEX_SHADER);
        const fragmentShader = compileShader(fragmentShaderSource, gl.FRAGMENT_SHADER);
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);

        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            console.error('Program link failed: ' + gl.getProgramInfoLog(program));
            throw new Error('Program link error');
        }
        gl.useProgram(program);

        // Set up geometry
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
            -1, -1,
            1, -1,
            -1, 1,
            -1, 1,
            1, -1,
            1, 1,
        ]), gl.STATIC_DRAW);

        const positionLocation = gl.getAttribLocation(program, 'a_position');
        gl.enableVertexAttribArray(positionLocation);
        gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

        // Set up uniforms
        const timeLocation = gl.getUniformLocation(program, 'u_time');
        const resolutionLocation = gl.getUniformLocation(program, 'u_resolution');
        const audioLocation = gl.getUniformLocation(program, 'u_audio');
        const orientationLocation = gl.getUniformLocation(program, 'u_orientation');
        const touchLocation = gl.getUniformLocation(program, 'u_touch');

        let audioLevel = 0.0;
        let orientation = { alpha: 0, beta: 0, gamma: 0 };
        let touch = [0.0, 0.0];

        // Set up microphone input
        navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then(stream => {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            analyser.fftSize = 256;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            function updateAudioData() {
                analyser.getByteFrequencyData(dataArray);
                audioLevel = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength / 256.0;

                // Trigger haptic feedback with stronger variation based on audio frequency bands
                if (navigator.vibrate) {
                    const lowFrequency = dataArray.slice(0, bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3);
                    const midFrequency = dataArray.slice(bufferLength / 3, 2 * bufferLength / 3).reduce((sum, value) => sum + value, 0) / (bufferLength / 3);
                    const highFrequency = dataArray.slice(2 * bufferLength / 3, bufferLength).reduce((sum, value) => sum + value, 0) / (bufferLength / 3);

                    const vibrationPattern = [];
                    if (lowFrequency > 10) {
                        vibrationPattern.push(Math.min(Math.floor(lowFrequency * 20), 500)); // Increased vibration intensity for better feedback
                    }
                    if (midFrequency > 10) {
                        vibrationPattern.push(Math.min(Math.floor(midFrequency * 15), 400)); // Increased vibration intensity for better feedback
                    }
                    if (highFrequency > 10) {
                        vibrationPattern.push(Math.min(Math.floor(highFrequency * 10), 300)); // Increased vibration intensity for better feedback
                    }

                    if (vibrationPattern.length > 0) {
                        navigator.vibrate(vibrationPattern);
                    }
                }

                requestAnimationFrame(updateAudioData);
            }
            updateAudioData();
        }).catch(err => {
            console.error('Error accessing microphone: ' + err);
        });

        // Set up device orientation
        window.addEventListener('deviceorientation', (event) => {
            orientation.alpha = event.alpha;
            orientation.beta = event.beta;
            orientation.gamma = event.gamma;
        });

        // Set up touch interaction
        canvas.addEventListener('touchmove', (event) => {
            const touchEvent = event.touches[0];
            touch = [
                (touchEvent.clientX / window.innerWidth) * 2.0 - 1.0,
                1.0 - (touchEvent.clientY / window.innerHeight) * 2.0
            ];
        });

        // Render loop
        function render(time) {
            time *= 0.001; // Convert time to seconds

            // Clear canvas
            gl.clearColor(0, 0, 0, 1);
            gl.clear(gl.COLOR_BUFFER_BIT);

            // Set uniforms
            gl.uniform1f(timeLocation, time);
            gl.uniform2f(resolutionLocation, canvas.width, canvas.height);
            gl.uniform1f(audioLocation, audioLevel);

            // Normalize orientation values and set uniform
            const orientationVec = [
                orientation.gamma / 90.0,  // X-axis tilt normalized to [-1, 1]
                orientation.beta / 90.0,   // Y-axis tilt normalized to [-1, 1]
                orientation.alpha / 360.0  // Z-axis rotation normalized to [0, 1]
            ];
            gl.uniform3fv(orientationLocation, orientationVec);

            // Set touch uniform
            gl.uniform2fv(touchLocation, touch);

            // Draw
            gl.drawArrays(gl.TRIANGLES, 0, 6);

            requestAnimationFrame(render);
        }
        requestAnimationFrame(render);
    </script>
</body>
</html>
