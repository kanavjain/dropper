<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU Visualizer with Framer Motion UI</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: black; }
        canvas { display: block; }
        #ui {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
        }
        #slider {
            width: 200px;
        }
    </style>
</head>
<body>
    <div id="ui">
        <input id="slider" type="range" min="1" max="100" value="50">
    </div>

    <script type="module">
        import { motion } from 'https://cdn.jsdelivr.net/npm/framer-motion/+esm';
        import * as THREE from 'https://cdnjs.cloudflare.com/ajax/libs/three.js/0.169.0/three.module.js';
        import { WebGPURenderer } from 'https://cdnjs.cloudflare.com/ajax/libs/three.js/0.169.0/three.webgpu.min.js';

        let scene, camera, renderer;
        let analyser, dataArray, torusKnot, particleSystem;
        let audioContext, source;
        let sensitivity = 50;

        // Framer Motion animated slider
        const slider = document.querySelector("#slider");
        slider.addEventListener("input", (e) => {
            sensitivity = e.target.value;
        });

        async function init() {
            if (!navigator.gpu) {
                alert("WebGPU is not supported in this browser. Please use a browser with WebGPU support.");
                return;
            }

            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 100;

            renderer = new WebGPURenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            createFunkyGeometry();

            try {
                await getMicrophoneInput();
            } catch (error) {
                alert('Microphone access is required for the visualizer.');
                console.error('Error accessing microphone:', error);
            }

            window.addEventListener('resize', onWindowResize, false);

            animate();
        }

        function createFunkyGeometry() {
            // Torus Knot
            const torusKnotGeometry = new THREE.TorusKnotGeometry(10, 3, 100, 16);
            const torusKnotMaterial = new THREE.MeshBasicMaterial({ color: 0xff8800, wireframe: true });
            torusKnot = new THREE.Mesh(torusKnotGeometry, torusKnotMaterial);
            scene.add(torusKnot);

            // Particle System
            const particleCount = 2000;
            const particles = new THREE.BufferGeometry();
            const positions = new Float32Array(particleCount * 3);
            for (let i = 0; i < particleCount * 3; i++) {
                positions[i] = (Math.random() - 0.5) * 200;
            }
            particles.setAttribute('position', new THREE.BufferAttribute(positions, 3));

            const particleMaterial = new THREE.PointsMaterial({
                color: 0x22ff22,
                size: 3,
                transparent: true,
                blending: THREE.AdditiveBlending,
            });
            particleSystem = new THREE.Points(particles, particleMaterial);
            scene.add(particleSystem);
        }

        async function getMicrophoneInput() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log("Microphone access granted.");
                
                source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);
                source.connect(analyser);
            } catch (err) {
                console.error("Error accessing microphone:", err);
                alert("Microphone access was blocked. Please enable it and reload.");
            }
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            requestAnimationFrame(animate);

            if (analyser) {
                analyser.getByteFrequencyData(dataArray);

                // Use sensitivity slider to control response
                const midFreq = dataArray[100] / 255 * sensitivity / 100;
                torusKnot.rotation.x += 0.01 + midFreq * 0.1;
                torusKnot.rotation.y += 0.01 + midFreq * 0.1;

                particleSystem.material.size = (dataArray[150] / 255) * sensitivity / 10;
                particleSystem.material.color.setHSL(dataArray[150] / 255, 1.0, 0.5);
            }

            renderer.render(scene, camera);
        }

        init();
    </script>
</body>
</html>
